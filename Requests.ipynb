{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Handle New Data Requests Automatically\n",
    "- beginning of notebook is assumed to be interactive until the requests have been checked\n",
    "- all progress and exception logging is done only for main loop\n",
    "- copy and paste the e-mail response and send from gcs.cmip6.ldeo@gmail.com account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myconfig\n",
    "from mytasks import Check, Download, ReadFiles, SaveAsZarr, Upload, Cleanup\n",
    "from mysearch import esgf_search\n",
    "from myrequest import requests, set_request_id\n",
    "from myresponse import response, get_details, dict_to_dfcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zarrs will be written to:  /h112/naomi/zarr-minimal/\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURE ESGF Search here\n",
    "node_pref = myconfig.node_pref\n",
    "dtype = myconfig.dtype\n",
    "myconfig.local_target_prefix = '/h113/naomi/zarr-minimal/'\n",
    "\n",
    "# reset the preference rank to omit a particular data node\n",
    "# node_pref['esgf-data1.llnl.gov'] = 999\n",
    "\n",
    "ESGF_site = dtype['llnl']\n",
    "#ESGF_site = dtype['dkrz']\n",
    "\n",
    "print('zarrs will be written to: ',myconfig.local_target_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE GCS\n",
    "fs     = gcsfs.GCSFileSystem(token='anon', access='read_only',cache_timeout=-1)\n",
    "df_GCS = pd.read_csv('https://cmip6.storage.googleapis.com/cmip6-zarr-consolidated-stores-noQC.csv', dtype='unicode')\n",
    "\n",
    "# make available to all modules\n",
    "myconfig.fs = fs\n",
    "myconfig.df_GCS = df_GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get new Google Sheet requests\n",
    "- by default, only the new rows from the sheet are considered\n",
    "- specifying a list of rows or emails will add older entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nadiakiran.gis@gmail.com 211 ['Warning: variable_id=pr is not available in table_id=fx', 'Warning: variable_id=tasmax is not available in table_id=fx', 'Warning: variable_id=tasmin is not available in table_id=fx']\n",
      "{'nadiakiran.gis@gmail.com_211': ['Warning: variable_id=pr is not available in table_id=fx', 'Warning: variable_id=tasmax is not available in table_id=fx', 'Warning: variable_id=tasmin is not available in table_id=fx']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>E-mail</th>\n",
       "      <th>response status</th>\n",
       "      <th>members</th>\n",
       "      <th>experiments</th>\n",
       "      <th>models</th>\n",
       "      <th>variables</th>\n",
       "      <th>table</th>\n",
       "      <th>requester</th>\n",
       "      <th>science</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/11/2019 18:25:47</td>\n",
       "      <td>nhn2@columbia.edu</td>\n",
       "      <td>once</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[historical]</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[ps, hus, ua, va, ta]</td>\n",
       "      <td>Amon</td>\n",
       "      <td>Naomi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12/8/2020 4:47:14</td>\n",
       "      <td>hiba.omrani@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[historical, ssp126, ssp245, ssp370, ssp585]</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[tas, pr, tasmax, tasmin, uas, vas]</td>\n",
       "      <td>day</td>\n",
       "      <td>Hiba Omrani</td>\n",
       "      <td>climat impact studies</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>12/11/2020 16:47:24</td>\n",
       "      <td>Hassanakbari22@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[1pctCO2-cdr]</td>\n",
       "      <td>[FGOALS-f3-L]</td>\n",
       "      <td>[yes]</td>\n",
       "      <td>CFday</td>\n",
       "      <td>Hassan Akbari</td>\n",
       "      <td>CMPI6, Research</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>12/13/2020 14:07:05</td>\n",
       "      <td>nadiakiran.gis@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[1pctCO2, abrupt-4xCO2, amip, esm-hist, esm-pi...</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[pr, tasmax, tasmin]</td>\n",
       "      <td>fx</td>\n",
       "      <td>Syeda Nadia Kiran</td>\n",
       "      <td>impacts of climate change on flood</td>\n",
       "      <td>I want to process CMIP6 data to assess the imp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp                    E-mail response status members                                        experiments         models                            variables  table          requester                             science                                           comments\n",
       "3     9/11/2019 18:25:47         nhn2@columbia.edu            once   [All]                                       [historical]          [All]                [ps, hus, ua, va, ta]   Amon              Naomi                                 NaN                                                NaN\n",
       "209    12/8/2020 4:47:14     hiba.omrani@gmail.com             NaN   [All]       [historical, ssp126, ssp245, ssp370, ssp585]          [All]  [tas, pr, tasmax, tasmin, uas, vas]    day        Hiba Omrani               climat impact studies                                                NaN\n",
       "210  12/11/2020 16:47:24  Hassanakbari22@gmail.com             NaN   [All]                                      [1pctCO2-cdr]  [FGOALS-f3-L]                                [yes]  CFday      Hassan Akbari                     CMPI6, Research                                                NaN\n",
       "211  12/13/2020 14:07:05  nadiakiran.gis@gmail.com             NaN   [All]  [1pctCO2, abrupt-4xCO2, amip, esm-hist, esm-pi...          [All]                 [pr, tasmax, tasmin]     fx  Syeda Nadia Kiran  impacts of climate change on flood  I want to process CMIP6 data to assess the imp..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>E-mail</th>\n",
       "      <th>response status</th>\n",
       "      <th>members</th>\n",
       "      <th>experiments</th>\n",
       "      <th>models</th>\n",
       "      <th>variables</th>\n",
       "      <th>table</th>\n",
       "      <th>requester</th>\n",
       "      <th>science</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>12/13/2020 14:07:05</td>\n",
       "      <td>nadiakiran.gis@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[1pctCO2, abrupt-4xCO2, amip, esm-hist, esm-pi...</td>\n",
       "      <td>[All]</td>\n",
       "      <td>[pr, tasmax, tasmin]</td>\n",
       "      <td>fx</td>\n",
       "      <td>Syeda Nadia Kiran</td>\n",
       "      <td>impacts of climate change on flood</td>\n",
       "      <td>I want to process CMIP6 data to assess the imp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp                    E-mail response status members                                        experiments models             variables table          requester                             science                                           comments\n",
       "211  12/13/2020 14:07:05  nadiakiran.gis@gmail.com             NaN   [All]  [1pctCO2, abrupt-4xCO2, amip, esm-hist, esm-pi...  [All]  [pr, tasmax, tasmin]    fx  Syeda Nadia Kiran  impacts of climate change on flood  I want to process CMIP6 data to assess the imp..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prior = pd.read_csv('csv/requests.csv')\n",
    "\n",
    "rows = []   \n",
    "emails = []\n",
    "rows = [3] #range(0,5) #[0,5,9]\n",
    "#emails = ['c.wang@princeton.edu']\n",
    "\n",
    "df_request_new, dtrouble = requests(df_prior,rows=rows,emails=emails)\n",
    "request_id = set_request_id()\n",
    "\n",
    "# Check for mal-formed requests (non-existent variables, etc)\n",
    "if len(dtrouble)>=1:\n",
    "    print(dtrouble)\n",
    "\n",
    "# print all active requests:\n",
    "display(df_request_new)\n",
    "\n",
    "# by index\n",
    "#type = 'input'\n",
    "type = 'last'\n",
    "\n",
    "if type == 'input':\n",
    "    resp = input('index?  (after entering number, click on next cell to advance)')\n",
    "    df_request_new = df_request_new.loc[[int(resp)]]\n",
    "else:\n",
    "    timestamps = df_request_new.Timestamp.unique()\n",
    "    df_request_new = df_request_new[df_request_new.Timestamp == timestamps[-1]]\n",
    "\n",
    "df_request_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('request-211',\n",
       " {'table_id': ['fx'],\n",
       "  'experiment_id': ['1pctCO2',\n",
       "   'abrupt-4xCO2',\n",
       "   'amip',\n",
       "   'esm-hist',\n",
       "   'esm-piControl',\n",
       "   'historical',\n",
       "   'lgm',\n",
       "   'past1000',\n",
       "   'piControl',\n",
       "   'ssp126',\n",
       "   'ssp245',\n",
       "   'ssp370',\n",
       "   'ssp585'],\n",
       "  'variable_id': ['pr', 'tasmax', 'tasmin']})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_search = {}\n",
    "search_keys = {'table':'table_id','experiments':'experiment_id','variables':'variable_id','models':'source_id','members':'member_id'}\n",
    "\n",
    "for item, row in df_request_new.iterrows():\n",
    "    all_search['table_id'] = [row.table]\n",
    "    request = item\n",
    "    for key in search_keys.keys():\n",
    "        if key == 'table':\n",
    "            continue\n",
    "        klist = row[key]\n",
    "        if not ('All' in klist)|('One' in klist):  # Note, we no longer get just one member_id without specifying which\n",
    "            all_search[search_keys[key]] = klist\n",
    "\n",
    "label = f'request-{request}'\n",
    "\n",
    "label, all_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table_id': 'fx', 'experiment_id': '1pctCO2', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': '1pctCO2', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': '1pctCO2', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'abrupt-4xCO2', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'abrupt-4xCO2', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'abrupt-4xCO2', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'amip', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'amip', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'amip', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'esm-hist', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'esm-hist', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'esm-hist', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'esm-piControl', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'esm-piControl', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'esm-piControl', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'historical', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'historical', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'historical', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'lgm', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'lgm', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'lgm', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'past1000', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'past1000', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'past1000', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'piControl', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'piControl', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'piControl', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp126', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp126', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp126', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp245', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp245', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp245', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp370', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp370', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp370', 'variable_id': 'tasmin'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp585', 'variable_id': 'pr'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp585', 'variable_id': 'tasmax'}\n",
      "empty search response\n",
      "{'table_id': 'fx', 'experiment_id': 'ssp585', 'variable_id': 'tasmin'}\n",
      "empty search response\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e13851c9a8d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mdESGF\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf_ESGF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdESGF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdf_ESGF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'csv/ESGF_{label}.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-fall2020/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-fall2020/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "update_ESGF = True\n",
    "if update_ESGF:\n",
    "    x = [value for key,value in all_search.items()]\n",
    "    searches = [p for p in itertools.product(*x)]\n",
    "\n",
    "    dESGF = []\n",
    "    for s in searches:\n",
    "        search = dict(zip(all_search.keys(),s))\n",
    "        print(search)\n",
    "        df = esgf_search(search, server=ESGF_site)\n",
    "        if len(df)>0:\n",
    "            dESGF += [df]\n",
    "\n",
    "    df_ESGF = pd.concat(dESGF)\n",
    "    df_ESGF.to_csv(f'csv/ESGF_{label}.csv',index=False)\n",
    "else:\n",
    "    df_ESGF = pd.read_csv(f'csv/ESGF_{label}.csv', dtype='unicode')\n",
    "\n",
    "len(df_ESGF), len(df_ESGF.ds_dir.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df of all needed\n",
    "NewNeeded = True\n",
    "if NewNeeded:\n",
    "    df = pd.merge(df_ESGF,df_GCS, how='outer', indicator=True)\n",
    "    df_needed = df[df._merge == 'left_only']\n",
    "    \n",
    "    keep_keys = df_ESGF.keys()\n",
    "    all_keys = df.keys()\n",
    "    drop_keys = list(set(all_keys) - set(keep_keys))\n",
    "    df_needed = df_needed.drop(drop_keys,1)\n",
    "\n",
    "    num_stores = 0\n",
    "    if len(df_needed) > 0:\n",
    "        num_stores = df_needed.ds_dir.nunique() \n",
    "        print(f'needed: nfiles={len(df_needed)}, nstores={num_stores}')\n",
    "    else:\n",
    "        print('no new data available')\n",
    "        exit    \n",
    "    \n",
    "    df_needed['member'] = [int(s.split('r')[-1].split('i')[0]) for s in df_needed['member_id']]\n",
    "    df_needed['zsize'] = [df_needed[df_needed.ds_dir==zs]['file_size'].sum() for zs in df_needed['ds_dir']]\n",
    "    df_needed = df_needed.sort_values(by=['zsize'])\n",
    "    \n",
    "    df_needed.to_csv(f'csv/needed_{label}.csv',index=False)\n",
    "else:\n",
    "    df_needed = pd.read_csv(f'csv/needed_{label}.csv')\n",
    "\n",
    "len(df_needed), len(df_needed.ds_dir.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make available to all modules\n",
    "myconfig.df_needed = df_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dirs = df_needed.ds_dir.unique()\n",
    "numdsets = len(ds_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_id = 'test' #datetime.now().strftime('%Y%m%d-%H%M')\n",
    "progress_log  = f'logs/progress_{label}.log'\n",
    "failure_log  = f'logs/failure_{label}.log'\n",
    "success_log  = f'logs/success_{label}.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(file,str,verbose=False):\n",
    "    f = open(file,'a')\n",
    "    if verbose:\n",
    "        print(str)\n",
    "    f.write(f'{str}\\n')\n",
    "    f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the catalog\n",
    "df_GCS = pd.read_csv('https://cmip6.storage.googleapis.com/cmip6-zarr-consolidated-stores-noQC.csv', dtype='unicode')\n",
    "\n",
    "# refresh the gcsfs\n",
    "fs.invalidate_cache()\n",
    "\n",
    "verbose = False\n",
    "zdict = {}\n",
    "for item, ds_dir in enumerate(ds_dirs):\n",
    "    #if item > 0:\n",
    "    #    continue\n",
    "    print(f'\\n{item}/{numdsets-1}',ds_dir)\n",
    "\n",
    "    (ierr, exc) = Check(ds_dir)\n",
    "    if ierr > 0:\n",
    "        write_log(progress_log,f'{ds_dir} {ierr}: {exc}',verbose=verbose); continue\n",
    "        \n",
    "    (gfiles, ierr, exc) = Download(ds_dir)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir},noUse, {ierr}: {exc}',verbose=verbose); continue\n",
    "        \n",
    "    (ds, ierr, exc) = ReadFiles(ds_dir, gfiles)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir},noUse, {ierr}: {exc}',verbose=verbose); continue\n",
    "\n",
    "    (ierr, exc) = SaveAsZarr(ds_dir, ds)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir},noUse, {ierr}: {exc}',verbose=verbose); continue\n",
    "        \n",
    "    (gsurl, ierr, exc) = Upload(ds_dir)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir},noUse, {ierr}: {exc}',verbose=verbose); continue\n",
    "\n",
    "    (ierr, exc) = Cleanup(ds_dir, gfiles)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir},noUse, {ierr}: {exc}',verbose=verbose); continue\n",
    "\n",
    "    vlist = get_details(ds_dir, ds)\n",
    "    zdict[item] = vlist\n",
    "    \n",
    "    write_log(success_log,f'{item}/{numdsets-1}: {ds_dir} saved to {gsurl}',verbose=verbose); continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a table of acquired data to send in email to requestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(zdict) == 0 :\n",
    "    print('nothing else to do')\n",
    "    exit\n",
    "else:\n",
    "    dz = dict_to_dfcat(zdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz.zstore.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_master_new = pd.concat([df_GCS, dz],sort=True)\n",
    "except:\n",
    "    df_master_new = df_GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re: CMIP6 GCS Data Request (Responses)\n",
      "Dear Syeda Nadia Kiran:\n",
      "\n",
      "  Here are the results from your recent CMIP6 data request(s).  The master catalog, https://cmip6.storage.googleapis.com/cmip6-zarr-consolidated-stores.csv, will be updated with the nightly build.\n",
      "\n",
      "  Please note: \n",
      "      - Data for some models (e.g., CAS/FGOALS-f3-L and NUIST/NESM3) must be obtained directly from servers which are too slow or unresponsive. \n",
      "      - We exclude data with known errors (as reported at ES-DOC) from the official listing at https://errata.es-doc.org/ .\n",
      "        However, data labelled status=resolved or severity=low are included in the master catalog.\n",
      "      - Some data we have not been able to clean up enough to get it concatenated and save to zarr. Other datasets are only available for disjointed time periods.\n",
      "\n",
      "  See the sample Jupyter Notebook at https://gist.github.com/naomi-henderson/ed1801d8ee8b992dda252f8b126876a5 for a quick introduction to accessing the data.\n",
      "\n",
      "From the folks at:\n",
      "  The Climate Data Science Lab\n",
      "  Division of Ocean and Climate Physics\n",
      "  LDEO/Columbia University\n",
      "\n",
      "--------------------------\n",
      "\n",
      "request:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Timestamp': '12/13/2020 14:07:05',\n",
       " 'E-mail': 'nadiakiran.gis@gmail.com',\n",
       " 'members': ['All'],\n",
       " 'experiments': ['1pctCO2',\n",
       "  'abrupt-4xCO2',\n",
       "  'amip',\n",
       "  'esm-hist',\n",
       "  'esm-piControl',\n",
       "  'historical',\n",
       "  'lgm',\n",
       "  'past1000',\n",
       "  'piControl',\n",
       "  'ssp126',\n",
       "  'ssp245',\n",
       "  'ssp370',\n",
       "  'ssp585'],\n",
       " 'models': ['All'],\n",
       " 'variables': ['pr', 'tasmax', 'tasmin'],\n",
       " 'table': 'fx',\n",
       " 'requester': 'Syeda Nadia Kiran',\n",
       " 'science': 'impacts of climate change on flood',\n",
       " 'comments': 'I want to process CMIP6 data to assess the impact of climate change on flooding'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response:\n",
      "no new data available at ESGF API search node https://esgf-node.llnl.gov/esg-search/search\n",
      "3418 fx\n",
      "2555 ['1pctCO2', 'abrupt-4xCO2', 'amip', 'esm-hist', 'esm-piControl', 'historical', 'lgm', 'past1000', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "0 ['pr', 'tasmax', 'tasmin']\n",
      "\n",
      "available data:\n",
      "  this includes your new stores but does not include datasets marked 'onhold', 'wontfix' or 'new' in the ES-DOC ERRATA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ldict = []\n",
    "names = \"\"\n",
    "print('Re: CMIP6 GCS Data Request (Responses)')\n",
    "for row in df_request_new.values:\n",
    "    rdict = dict(zip(df_request_new.keys(),row))\n",
    "    #print(rdict)\n",
    "    name = rdict['requester']\n",
    "    timestamp = rdict['Timestamp']\n",
    "    names += name\n",
    "    del rdict['response status']\n",
    "    ldict += [rdict]\n",
    "    dfr = df_request_new[df_request_new.Timestamp == timestamp]\n",
    "    \n",
    "    print('Dear',name+':')\n",
    "    print('\\n  Here are the results from your recent CMIP6 data request(s).  The master catalog, https://cmip6.storage.googleapis.com/cmip6-zarr-consolidated-stores.csv, will be updated with the nightly build.')\n",
    "    #if len(dtrouble)>=1:\n",
    "    #    print('\\n '+dtrouble)\n",
    "    print('\\n  Please note: ')\n",
    "    print('      - Data for some models (e.g., CAS/FGOALS-f3-L and NUIST/NESM3) must be obtained directly from servers which are too slow or unresponsive. ')\n",
    "    print('      - We exclude data with known errors (as reported at ES-DOC) from the official listing at https://errata.es-doc.org/ .')\n",
    "    print('        However, data labelled status=resolved or severity=low are included in the master catalog.')\n",
    "    \n",
    "\n",
    "    print('      - Some data we have not been able to clean up enough to get it concatenated and save to zarr. Other datasets are only available for disjointed time periods.')\n",
    "    print('\\n  See the sample Jupyter Notebook at https://gist.github.com/naomi-henderson/ed1801d8ee8b992dda252f8b126876a5 for a quick introduction to accessing the data.')\n",
    "    print('\\nFrom the folks at:\\n  The Climate Data Science Lab\\n  Division of Ocean and Climate Physics\\n  LDEO/Columbia University')\n",
    "    print('\\n--------------------------')\n",
    "\n",
    "    print('\\nrequest:')\n",
    "    display(rdict)\n",
    "\n",
    "    print('\\nresponse:')\n",
    "    try:\n",
    "        print('new stores added:\\n',len(dz),'\\n')\n",
    "    except:\n",
    "        print(f'no new data available at ESGF API search node {ESGF_site}')\n",
    "\n",
    "    #print('\\n',dfr,len(df_master_new))\n",
    "    table = response(dfr,df_master_new)\n",
    "\n",
    "    print(\"\\navailable data:\\n  this includes your new stores but does not include datasets marked 'onhold', 'wontfix' or 'new' in the ES-DOC ERRATA\")\n",
    "    display(table)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-fall2020",
   "language": "python",
   "name": "pangeo-fall2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
