{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "xr.set_options(display_style='html')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy\n",
    "from myconfig import target_keys, target_format, node_pref\n",
    "\n",
    "# Author: Unknown\n",
    "# I got the original version from a word document published by ESGF\n",
    "# https://docs.google.com/document/d/1pxz1Kd3JHfFp8vR2JCVBfApbsHmbUQQstifhGNdc6U0/edit?usp=sharing\n",
    "# API AT: https://github.com/ESGF/esgf.github.io/wiki/ESGF_Search_REST_API#results-pagination\n",
    "\n",
    "def esgf_search(server=\"https://esgf-node.llnl.gov/esg-search/search\",\n",
    "                files_type=\"HTTPServer\", local_node=True, project=\"CMIP6\", page_size=500,\n",
    "                verbose=False, format=\"application%2Fsolr%2Bjson\", \n",
    "                 **search):\n",
    "    client = requests.session()\n",
    "    payload = search\n",
    "    payload[\"project\"] = project\n",
    "    payload[\"type\"]= \"File\"\n",
    "    if local_node:\n",
    "        payload[\"distrib\"] = \"false\"\n",
    "\n",
    "    payload[\"format\"] = format\n",
    "    payload[\"limit\"] = 500\n",
    "\n",
    "    numFound = 10000\n",
    "    all_frames = []\n",
    "    offset = 0\n",
    "    while offset < numFound:\n",
    "        payload[\"offset\"] = offset\n",
    "        url_keys = []\n",
    "        for k in payload:\n",
    "            url_keys += [\"{}={}\".format(k, payload[k])]\n",
    "\n",
    "        url = \"{}/?{}\".format(server, \"&\".join(url_keys))\n",
    "        r = client.get(url)\n",
    "        r.raise_for_status()\n",
    "        resp = r.json()[\"response\"]\n",
    "        numFound = int(resp[\"numFound\"])\n",
    "        \n",
    "        resp = resp[\"docs\"]\n",
    "        offset += len(resp)\n",
    "        #print(offset,numFound,len(resp))\n",
    "        for d in resp:\n",
    "            dataset_id = d[\"dataset_id\"]\n",
    "            dataset_size = d[\"size\"]\n",
    "            for f in d[\"url\"]:\n",
    "                sp = f.split(\"|\")\n",
    "                if sp[-1] == 'HTTPServer':\n",
    "                    dataset_url = sp[0]\n",
    "            all_frames += [[dataset_id,dataset_url,dataset_size]]\n",
    "        \n",
    "    ddict = {}\n",
    "    item = 0\n",
    "    for item, alist in enumerate(all_frames):\n",
    "        dataset_id = alist[0]\n",
    "        dataset_url = alist[1]\n",
    "        dataset_size = alist[2]\n",
    "        vlist = dataset_id.split('|')[0].split('.')[-9:]\n",
    "        vlist += [dataset_url.split('/')[-1]]\n",
    "        vlist += [dataset_size]\n",
    "        vlist += [dataset_url]\n",
    "        vlist += [dataset_id.split('|')[-1]]\n",
    "        ddict[item] = vlist\n",
    "        item += 1\n",
    "\n",
    "    dz = pd.DataFrame.from_dict(ddict, orient='index')\n",
    "    dz = dz.rename(columns={0: \"activity_id\", 1: \"institution_id\", 2:\"source_id\",\n",
    "                            3:\"experiment_id\",4:\"member_id\",5:\"table_id\",6:\"variable_id\",\n",
    "                            7:\"grid_label\",8:\"version_id\",9:\"ncfile\",10:\"size\",11:\"url\",12:\"data_node\"})\n",
    "\n",
    "    dz['zstore'] = dz.apply(lambda row: target_format % row,axis=1)\n",
    "    dz['node_order'] = [node_pref[s] for s in dz.data_node ]\n",
    "\n",
    "    return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 17092 500\n",
      "1000 17092 500\n",
      "1500 17092 500\n",
      "2000 17092 500\n",
      "2500 17092 500\n",
      "3000 17092 500\n",
      "3500 17092 500\n",
      "4000 17092 500\n",
      "4500 17092 500\n",
      "5000 17092 500\n",
      "5500 17092 500\n",
      "6000 17092 500\n",
      "6500 17092 500\n",
      "7000 17092 500\n",
      "7500 17092 500\n",
      "8000 17092 500\n",
      "8500 17092 500\n",
      "9000 17092 500\n",
      "9500 17092 500\n",
      "10000 17092 500\n",
      "10500 17092 500\n",
      "11000 17092 500\n",
      "11500 17092 500\n",
      "12000 17092 500\n",
      "12500 17092 500\n",
      "13000 17092 500\n",
      "13500 17092 500\n",
      "14000 17092 500\n",
      "14500 17092 500\n",
      "15000 17092 500\n",
      "15500 17092 500\n",
      "16000 17092 500\n",
      "16500 17092 500\n",
      "17000 17092 500\n",
      "17092 17092 92\n"
     ]
    }
   ],
   "source": [
    "df_esgf = esgf_search(table_id='Amon', variable_id='tas', experiment_id='historical')\n",
    "\n",
    "df_esgf = df_esgf.drop_duplicates(subset =[\"zstore\",\"ncfile\"],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, 10,  6,  5,  4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_esgf.node_order.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-fall2020",
   "language": "python",
   "name": "pangeo-fall2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
