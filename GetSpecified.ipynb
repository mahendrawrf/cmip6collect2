{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "import myconfig\n",
    "from mytasks import Check, Download, ReadFiles, SaveAsZarr, Upload, Cleanup\n",
    "from mysearch import esgf_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zarrs will be written to:  /h111/naomi/zarr-minimal/\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURE ESGF Search here\n",
    "\n",
    "import myconfig\n",
    "node_pref = myconfig.node_pref\n",
    "dtype = myconfig.dtype\n",
    "\n",
    "# reset the preference rank to omit\n",
    "# node_pref['esgf-data1.llnl.gov'] = 999\n",
    "\n",
    "ESGF_site = dtype['llnl']\n",
    "#ESGF_site = dtype['dkrz']\n",
    "\n",
    "print('zarrs will be written to: ',myconfig.local_target_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE GCS\n",
    "fs     = gcsfs.GCSFileSystem(token='anon', access='read_only',cache_timeout=-1)\n",
    "df_GCS = pd.read_csv('https://cmip6.storage.googleapis.com/cmip6-zarr-consolidated-stores-noQC.csv', dtype='unicode')\n",
    "\n",
    "# make available to all modules\n",
    "myconfig.fs = fs\n",
    "myconfig.df_GCS = df_GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_experiments = ['ssp126','ssp245','ssp370','ssp585','ssp119','ssp434','ssp460','ssp534-over','1pctCO2','abrupt-4xCO2','amip','historical','piControl',\n",
    " 'esm-hist','esm-piControl','esm-piControl-spinup','piControl-spinup','amip-hist']\n",
    "core_Amon_vars = ['ts','psl','hfls','ps','sfcWind','uas','vas','tas','pr','prc','evspsbl']\n",
    "core_Omon_vars = ['tos','sos','zos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your search. not specifying means it will find all\n",
    "all_search = {\n",
    "     'table_id'      : ['Amon']\n",
    "    ,'experiment_id' : ['historical']\n",
    "    ,'variable_id'   : core_Amon_vars\n",
    "    #,'member_id'     : ['r1i1p1f1']\n",
    "    #,'source_id'     : ['CESM2-WACCM']\n",
    "}\n",
    "\n",
    "exp1 = all_search['experiment_id'][0]\n",
    "tab1 = all_search['table_id'][0]\n",
    "label = f'{exp1}-{tab1}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'ts'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'psl'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'hfls'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'ps'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'sfcWind'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'uas'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'vas'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'tas'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'pr'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'prc'}\n",
      "{'table_id': 'Amon', 'experiment_id': 'historical', 'variable_id': 'evspsbl'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(101282, 5689)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "update_ESGF = True\n",
    "if update_ESGF:\n",
    "    x = [value for key,value in all_search.items()]\n",
    "    searches = [p for p in itertools.product(*x)]\n",
    "\n",
    "    dESGF = []\n",
    "    for s in searches:\n",
    "        search = dict(zip(all_search.keys(),s))\n",
    "        print(search)\n",
    "        df = esgf_search(search, server=ESGF_site)\n",
    "        if len(df)>0:\n",
    "            dESGF += [df]\n",
    "\n",
    "    df_ESGF = pd.concat(dESGF)\n",
    "    df_ESGF.to_csv(f'csv/ESGF_{label}.csv',index=False)\n",
    "else:\n",
    "    exp1 = all_search['experiment_id'][0]\n",
    "    tab1 = all_search['table_id'][0]\n",
    "    df_ESGF = pd.read_csv(f'csv/ESGF_{label}.csv', dtype='unicode')\n",
    "\n",
    "len(df_ESGF), len(df_ESGF.ds_dir.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needed: nfiles=1352, nstores=19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1352, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make df of all needed\n",
    "NewNeeded = True\n",
    "if NewNeeded:\n",
    "    df = pd.merge(df_ESGF,df_GCS, how='outer', indicator=True)\n",
    "    df_needed = df[df._merge == 'left_only']\n",
    "    \n",
    "    keep_keys = df_ESGF.keys()\n",
    "    all_keys = df.keys()\n",
    "    drop_keys = list(set(all_keys) - set(keep_keys))\n",
    "    df_needed = df_needed.drop(drop_keys,1)\n",
    "\n",
    "    num_stores = 0\n",
    "    if len(df_needed) > 0:\n",
    "        num_stores = df_needed.ds_dir.nunique() \n",
    "        print(f'needed: nfiles={len(df_needed)}, nstores={num_stores}')\n",
    "    else:\n",
    "        print('no new data available')\n",
    "        exit    \n",
    "    \n",
    "    df_needed['member'] = [int(s.split('r')[-1].split('i')[0]) for s in df_needed['member_id']]\n",
    "    df_needed['zsize'] = [df_needed[df_needed.ds_dir==zs]['file_size'].sum() for zs in df_needed['ds_dir']]\n",
    "    df_needed = df_needed.sort_values(by=['zsize'])\n",
    "    \n",
    "    df_needed.to_csv(f'csv/needed_{label}.csv',index=False)\n",
    "else:\n",
    "    df_needed = pd.read_csv(f'csv/needed_{label}.csv')\n",
    "\n",
    "len(df_needed), len(df_needed.ds_dir.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make available to all modules\n",
    "myconfig.df_needed = df_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dirs = df_needed.ds_dir.unique()\n",
    "numdsets = len(ds_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_id = 'test' #datetime.now().strftime('%Y%m%d-%H%M')\n",
    "progress_log  = f'txt/progress_{label}.log'\n",
    "failure_log  = f'txt/failure_{label}.log'\n",
    "success_log  = f'txt/success_{label}.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(file,str,verbose=True):\n",
    "    f = open(file,'a')\n",
    "    if verbose:\n",
    "        print(str)\n",
    "    f.write(f'{datetime.now().strftime(\"%Y%m%d-%H%M\")}: {str}\\n')\n",
    "    f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/psl/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/psl/gn with error 1: noUse in codes\n",
      "\n",
      "1/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/pr/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/pr/gn with error 1: noUse in codes\n",
      "\n",
      "2/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/ts/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/ts/gn with error 1: noUse in codes\n",
      "\n",
      "3/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/prc/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/prc/gn with error 1: noUse in codes\n",
      "\n",
      "4/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/ps/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/ps/gn with error 1: noUse in codes\n",
      "\n",
      "5/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/evspsbl/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/evspsbl/gn with error 1: noUse in codes\n",
      "\n",
      "6/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/sfcWind/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/sfcWind/gn with error 1: noUse in codes\n",
      "\n",
      "7/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/vas/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/vas/gn with error 1: noUse in codes\n",
      "\n",
      "8/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/tas/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/tas/gn with error 1: noUse in codes\n",
      "\n",
      "9/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/uas/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/uas/gn with error 1: noUse in codes\n",
      "\n",
      "10/18 CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/hfls/gn\n",
      "call Check:\n",
      "CMIP/NASA-GISS/GISS-E2-1-G/historical/r7i1p3f1/Amon/hfls/gn with error 1: noUse in codes\n",
      "\n",
      "11/18 CMIP/EC-Earth-Consortium/EC-Earth3/historical/r24i1p1f1/Amon/psl/gr\n",
      "call Check:\n",
      "CMIP/EC-Earth-Consortium/EC-Earth3/historical/r24i1p1f1/Amon/psl/gr with error 1: noUse in codes\n",
      "\n",
      "12/18 CMIP/EC-Earth-Consortium/EC-Earth3/historical/r3i1p1f1/Amon/ps/gr\n",
      "call Check:\n",
      "CMIP/EC-Earth-Consortium/EC-Earth3/historical/r3i1p1f1/Amon/ps/gr with error 1: noUse in codes\n",
      "\n",
      "13/18 CMIP/EC-Earth-Consortium/EC-Earth3/historical/r3i1p1f1/Amon/prc/gr\n",
      "call Check:\n",
      "call Download:\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185001-185012.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185101-185112.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185201-185212.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185301-185312.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185401-185412.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185501-185512.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185601-185612.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185701-185712.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185801-185812.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_185901-185912.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186001-186012.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186101-186112.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186201-186212.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186301-186312.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186401-186412.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186501-186512.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186601-186612.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186701-186712.nc\n",
      "netcdfs/prc_Amon_EC-Earth3_historical_r3i1p1f1_gr_186801-186812.nc\n"
     ]
    }
   ],
   "source": [
    "for item, ds_dir in enumerate(ds_dirs):\n",
    "    \n",
    "    print(f'\\n{item}/{numdsets-1}',ds_dir)\n",
    "\n",
    "    (ierr, exc) = Check(ds_dir)\n",
    "    if ierr > 0:\n",
    "        write_log(progress_log,f'{ds_dir} with error {ierr}: {exc}'); continue\n",
    "        \n",
    "    (gfiles, ierr, exc) = Download(ds_dir)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir} with error {ierr}: {exc}'); continue\n",
    "        \n",
    "    (ds,ierr,exc) = ReadFiles(ds_dir, gfiles)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir} with error {ierr}: {exc}'); continue\n",
    "\n",
    "    (ierr,exc) = SaveAsZarr(ds_dir, ds)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir} with error {ierr}: {exc}'); continue\n",
    "        \n",
    "    (gsurl, ierr,exc) = Upload(ds_dir)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir} with error {ierr}: {exc}'); continue\n",
    "\n",
    "    (ierr,exc) = Cleanup(ds_dir, gfiles)\n",
    "    if ierr > 0:\n",
    "        write_log(failure_log,f'{ds_dir} with error {ierr}: {exc}'); continue\n",
    "\n",
    "    write_log(success_log,f'{item}/{numdsets-1}: {ds_dir} saved to {gsurl}'); continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-fall2020",
   "language": "python",
   "name": "pangeo-fall2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
